
---
title: "Assignment 4"
author: "Tanjina Islam, Miguel Morales Expósito and Carlos Perales Liñan, group 12"
date: "22 March 2018"
output:
  pdf_document:
    fig_caption: yes
fontsize: 11pt
highlight: tango
---
```{r,echo=FALSE, warning=FALSE,results='hide',message=FALSE}
options(digits = 3) #Showing only 3 decimals
library(multcomp)
library(lme4)
```


## Exercise 1

We load the data from the data source.
```{r}
flies = read.table("fruitflies.txt",header=TRUE);
```

### Task 1 

We add the logarithm of longevity in the data frame.

```{r}
fliesframe = data.frame(thorax=flies$thorax,longevity=flies$longevity,activity=flies$activity,loglongevity=log(flies$longevity))
fliesframe
```


### Task 2

```{r}
hist(fliesframe$thorax)
qqnorm(fliesframe$thorax)
```
The population of thorax does not seem normal.

```{r}
hist(fliesframe$loglongevity)
qqnorm(fliesframe$loglongevity)
```
The population of loglongevity does not seem normal.


### Task 3

We perfom an anova just considering the sexual activity
```{r}
fliesanova = lm(loglongevity~activity,data=fliesframe)
anova(fliesanova)
```
We get a p-value 1.798e-07, therefore, H0 is reject so we can say that sexual activity affects the longevity of the flies.


### Task 4

```{r}
summary(fliesanova)
```
According to the estimates longevity increases with sexual activity. 
..* High activity =  3.602
..* Low activity =  3.602 + 0.517 = 4.119
..* Isolated =  3.602 + 0.397 = 3.999


### Task 5

We make a 2-way anova.
```{r}
fliesframe$activity = as.factor(fliesframe$activity)
fliesframe$thorax = as.factor(fliesframe$thorax)

fliesanova2 = lm(loglongevity~activity+thorax,data = fliesframe) #Should I use * or +
anova(fliesanova2)
```
We obtain a p-value of 1.141e-13, therefore, we can say that activity has a main effect on longevity when we consider the thorax length.

### Task 6
First we calculate the average thorax length.
```{r}
fliesframe$thorax = as.numeric(fliesframe$thorax)
average_thorax = mean(fliesframe$thorax) 
fliesframe$thorax = as.factor(fliesframe$thorax)

```

We obtain an average of `r average_thorax`.

We obtain the summary.
```{r}
contrasts(fliesframe$thorax)=contr.sum
contrasts(fliesframe$activity)=contr.sum
summary(fliesanova2)
```
With the values thorax9 = 0.312 (for the acerage thorax length) and isolated-activity = -0.275, low-activity = 0.186 and high-activity = -(-0.275+0.186) = 0.089, we calculate the estimates for flies with average thorax..

Y~isolated,thorax9~ = 3.802 + 0.312 - 0.275 = 3.839
Y~low,thorax9~ = 3.802 + 0.312 + 0.186 = 4.3
Y~high,thorax9~ = 3.802 + 0.312 + 0.089 = 4.203

For the flies with smallest thorax we use the same estimates for activity but we use thorax1 = -0.545.

Y~isolated,thorax1~ = 3.802 - 0.545 - 0.275 = 2.982
Y~low,thorax1~ = 3.802 - 0.545 + 0.186 = 3.443
Y~high,thorax1~ = 3.802 - 0.545 + 0.089 = 3.346


### Task 7

In order to investigate graphically how does thorax length influence longevity, we separate in three different variables the data depending on the sexual activity.
```{r}
fliesframe$thorax = as.numeric(fliesframe$thorax)
flieshigh = fliesframe[which(fliesframe$activity=="high"),]
fliesisolated = fliesframe[which(fliesframe$activity=="isolated"),]
flieslow = fliesframe[which(fliesframe$activity=="low"),]
```

Now we plot the thorax length agains the loglongevity.
```{r}
plot(flieshigh$thorax,flieshigh$loglongevity,main="High activity with loglongevity")
plot(fliesisolated$thorax,fliesisolated$loglongevity,main="Isolated activity with loglongevity")
plot(flieslow$thorax,flieslow$loglongevity,main="Low activity with loglongevity")
```
We see that longevity increases with thorax length. We get higher longevity values for flies with low sexual activity and also for high sexual activity. The values seem to be lower when the flies have been isolated. 

### Task 8

The analysis with the thorax length should not be included because there should not be interaction between the sexual activity and the thorax length. This is because the experimenters randomly chose the sexual activity that the flies were going to have.


### Task 9

```{r}

qqnorm(residuals(fliesanova2))
```
The normality seems doubtful according to the qq-plot.

```{r}
plot(fitted(fliesanova2),residuals(fliesanova2))
```
The spread in the residuals seem to be bigger with bigger fitted values.

### Task 10

```{r}
fliesframe$activity=as.factor(fliesframe$longevity)
fliesaov = lm(longevity~thorax+activity,data=fliesframe)
drop1(fliesaov,type="F")
```


```{r}
qqnorm(residuals(fliesanova))
qqline(residuals(fliesanova))
```
The normality s doubtful. But it could be normal. It seems more normal than when using the logaritmic value of longevity.

```{r}
plot(fitted(fliesanova),residuals(fliesanova))
```
We cannot judge becasue the values are not spread in the x axis. This is a prove that using the logarithmic value was a good idea.

## Exercise 2

We load the data from the data source.
```{r}
expsi = read.table("psi.txt", header=TRUE)

```

### Task 1 

To help us on making some summaries, we divide the data in 2 groups: the students that received psi and the ones that didn't.
```{r}
nousepsi = expsi[which(expsi$psi == "0"),]
usepsi = expsi[which(expsi$psi == "1"),]

```

Next, we show some data summaries:
```{r}

hist(nousepsi$gpa, breaks = c(2.0, 2.5, 3.0, 3.5, 4.0, 4.5), xlab="GPA", ylab="N of students", main="GPA of students not receiving PSI")

hist(usepsi$gpa, breaks = c(2.0, 2.5, 3.0, 3.5, 4.0, 4.5), xlab="GPA", ylab="N of students", main="GPA of students receiving PSI")

boxplot(expsi$gpa, usepsi$gpa, nousepsi$gpa, main="GPA Boxplots", names=c("All", "PSI", "No PSI"));

qqnorm(nousepsi$gpa,  main="Q-Q Plot of Student's GPA without PSI") # doesn't look normal
qqline(nousepsi$gpa, col="red")

qqnorm(usepsi$gpa, main="Q-Q Plot of Student's GPA receiving PSI") # looks normal
qqline(usepsi$gpa, col="red")
```


### Task 2

We fit them into a linear regression model.

```{r}
expsiglm=glm(passed~psi+gpa,data=expsi,family=binomial)
summary(expsiglm)

```


### Task 3

As we can see in the summary of the linear model, the usage of psi increases the linear predictor by 2.338.

Knowing this, we can calculate that it increases odds of passing by exp^2.338 = 10.3604948382


### Task 4

With the summary from task 2, we can see the values that we need to estimate these probabilities.

*With psi and gpa = 3.0:* 

-11.602 + 2.338 + (3.063 * 3.0) = -0.075 
Probability = 1/(1 + e^0.075) = 0.4812588


*Without psi and gpa = 3.0:* 

-11.602 + (3.063 * 3.0) = -2.408 
Probability = 1/(1 + e^2.408) = 0.08256469


### Task 5

exp(intercept(which is supposedly psi0) − psi1?) = 1.786932. )


### Task 6

```{r}
x=matrix(c(3,15,8,6),2,2)
x
```

The number 15 are the students that didn't show improvement from the 18, whereas 3 are those who did show improvement. Similarly with the second column, only 8 out of 14 students showed improvement and the remaining 6 didn't.

With the observations above, we can claim that the first column contains the students not receiving psi and the second one shows the students receiving it. Furthermore, row 1 shows the students that improved and row 2 the number of students that didn't.

```{r, results='hide'}
fisher.test(x)

```

After running the Fisher test we can reach tot his conclusion: with p-value of [`r fisher.test(x)[[1]]`] we can reject the null hypothesis, which claims that the students receiving psi and the ones not receiving it have the same probablity of improvement.


### Task 7

I guess it's okay? Fishers test works with this kind of experiments
```{r}


```


### Task 8

Fishers is good for small counts in each 2x2 table cell. 
More exact than the other approach, ut it doesn't work with  big counts.



## Exercise 3

First of all, we load the data from the data source.
```{r}
africa_data = read.table("africa.txt", header = TRUE)
attach(africa_data)

```

### Task 1 



```{r}


```

#### Findings: 

### Task 2

```{r}


```

#### Findings: 

### Task 3

We perform Poisson regression on the data.
```{r}
africa_glm = glm(miltcoup~oligarchy+pollib+parties+pctvote+popn+size+numelec+numregim, family = poisson, data = africa_data)
summary(africa_glm)

```


### Task 4

Using the step-down approach, we will reduce the number of variables in our model.
```{r}
africa_glm_sd = glm(miltcoup~oligarchy+pollib+parties+pctvote+popn+size+numelec+numregim, family = poisson, data = africa_data)
summary(africa_glm_sd)

summary(africa_glm_sd)[[12]][35]

```
As we can see, the variable numelec has the highest p-value and since it is > 0.05, we discard it for the next iteration.


```{r}
africa_glm_sd = glm(miltcoup~oligarchy+pollib+parties+pctvote+popn+size+numregim, family = poisson, data = africa_data)
summary(africa_glm_sd)

summary(africa_glm_sd)[[12]][32]
```
In this iteration, numregim has the highest p-value and it is > 0.05. Hence, we discard it for the next iteration.


```{r}
africa_glm_sd = glm(miltcoup~oligarchy+pollib+parties+pctvote+popn+size, family = poisson, data = africa_data)
summary(africa_glm_sd)

summary(africa_glm_sd)[[12]][28] 
```
Here, size has the highest p-value . As we can see, this value is > 0.05. This means we will discard it for our model and proceed to the next iteration.


```{r}

africa_glm_sd = glm(miltcoup~oligarchy+pollib+parties+pctvote+popn, family = poisson, data = africa_data)
summary(africa_glm_sd)

summary(africa_glm_sd)[[12]][24]
```
We pick the highest p-value, the one of the variable popn. This value is > 0.05, so discard it for the next iteration.


```{r}
africa_glm_sd = glm(miltcoup~oligarchy+pollib+parties+pctvote, family = poisson, data = africa_data)
summary(africa_glm_sd)

summary(africa_glm_sd)[[12]][20]
```
Of all the variables, pctvote has the highest p-value. It is > 0.05. So we discard it for the next iteration.


```{r}
africa_glm_sd = glm(miltcoup~oligarchy+pollib+parties, family = poisson, data = africa_data)
summary(africa_glm_sd)
```
As we can see, all the p-values are now smaller than 0.05. Meaning that all the variables are significant for our model.


The resulting model of the step-down method is:

miltcoup = 0.25138 + 0.09262*oligarchy - 0.57410*pollib + 0.02206*parties + error


### Task 5

Next, we will show some diagnostic plots for our model.


#### Plots: Fitted vs Residuals

```{r}
plot(fitted(africa_glm_sd), residuals(africa_glm_sd)) 

```
We can't recognize any specific pattern. Data is scattered, and it's not visually good as it would suppose to be in linear regression model.

Because of this, we will take the logarithm to make the x-values fitted by a linear function in the plot. 


#### Plots: Logarithmic-Fitted values vs Residuals

```{r}
plot(log(fitted(africa_glm_sd)), residuals(africa_glm_sd))

```
The plot seems OK yet still no specific pattern. And still looks scattered.


#### Plots: Logarithmic-Fitted values vs Residuals with type = Response

```{r}
plot(log(fitted(africa_glm_sd)), residuals(africa_glm_sd, type = "response"))

```

###### Check Lec 10 slide: 41-43


#### Plots: Fitted vs Residuals in the Full Model

```{r}
plot(fitted(africa_glm), residuals(africa_glm))

```

#### Plots: Logarithmic-Fitted values vs Residuals in the Full Model

```{r}
plot(log(fitted(africa_glm)), residuals(africa_glm))

```

#### Plots: Logarithmic-Fitted values vs Residuals with type = Response in the Full Model

```{r}
plot(log(fitted(africa_glm)), residuals(africa_glm, type = "response"))

```
The plots look scattered. All of them follow a certain pattern in our model from task-4. After ploting using the full model, we found the same pattern there too.

Therefore, we can discard that the readon is that we deleted too many variables.

Now we will check normality assumption.
```{r}

shapiro.test(residuals(africa_glm_sd)) # p-value = 0.01 < 0.05 # Normality is doubtful

shapiro.test(residuals(africa_glm)) # p-value = 0.01 < 0.05 # Normaility is doubtful
```

```{r}
qqnorm(residuals(africa_glm_sd)) # doesn't seem normal
qqline(residuals(africa_glm_sd), col="red")
```

```{r}

qqnorm(residuals(africa_glm)) # doesn't seem normal
qqline(residuals(africa_glm), col="red")
```

In both models we got the same results. The plots that we generated for the model that we found in task-4 and for the full model with all explanatory variables followed same type of pattern. For these reasons, the assumption of normality (if any) is doubtful.

This means that the sample might not come from a normal distribution.



